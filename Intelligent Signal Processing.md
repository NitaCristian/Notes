Intelligent signal processing involves:
- capturing
- storing
- playing
- processing 
- extracting 
information from various signals found in the world using a computer system.

# Sound

## Physics

Sound:
- is a form of energy produced by vibrating matter
- is a mechanical energy that needs a medium to propagate
- can travel through solids, liquids, and gases in form of mechanical waves
- can't travel in a vacuum, in contrast to electromagnetic energy

## Psychology

Sound:
- is the reception of sound waves and their procession by the brain
- arrive through the ears
- is converted to nerve in impulses interpreted by the brain

## Characteristics

- Velocity 
- Wavelength
- Frequency
- Time period
- Amplitude

The vibration creates in the surrounding area a series of alternative: 
- high pressured regions --> compressions
- low pressure regions --> rarefactions
that travel away at a certain speed.

Sound waves:
- transfer energy but not matter
- can be represented as a function which ranges over particle density or pressure values across the domain of distance
- can also be represented as a function across the domain of time

Speed of sound depends on:
- the elasticity
- the density
- the temperature 
of the median the sound is traveling through.

Example:
- Air 0°C --> speed = 331 m/s
  Distance between a man and a bell is 33.1 meters, he will hear the bell in 100 ms
  Density changes with the temperature, greater density --> faster speed of sound
- Air 20°C --> less dense --> slower speed of sound
- Sea water 20°C --> 1540 m/s
- Steel 0°C --> 5960 m/s

Wavelength:
- the distance between two successive crests or troughs of a wave
- higher frequencies correspond to shorter wavelengths.

Amplitude:
- is the maximum change in pressure or density that the vibrating object produces

Pressure is measured in pascals.Although for practical reasons for maturing sound amplitude, we usually use a logarithm ratio scale, the dB SPL scale.

Frequency:
- is the number of times per second that a sound pressure waves repeats itself
- the repetitions are known as cycles
- measured in hertz or cycles per second

Time period:
- the duration of each cycle
- can be found by measuring the time between successive high or low pressure points
- period is the inverse of the frequency

The period (T) is the inverse of the frequency (f):
$$
T = \frac{1}{f} \quad f = \frac{1}{T}
$$
Example:

$$
T = 0.1s \quad f = \frac{1}{0.1s} = 10 Hz
$$

Direct relation between sound speed (v), wavelength ($\lambda$) and frequency (f):
$$
v = f \cdot \lambda
$$

$$
\lambda = 2m \quad v = 4 \frac{m}{s} \quad 4 = f \cdot 2 \quad f = \frac{4 \frac{m}{s}}{2m} = 2Hz
$$
## Human perception

Perceptual properties:
- pitch
- loudness
- timbre 

Pitch:
- classify sounds as higher or lower
- frequency relates to pitch.
- change in frequency does not always correspond to constant change in pitch

Loudness:
- order sounds on a scale from quiet to loud
- amplitude relates to loudness.

Timbre (tone quality):
- distinguish sounds which have same pitch and loudness
- waveform relates to timbre.

All of the physical and perceptual properties relate to each other.

Pure tone
- sound that can be represented by a sinus function
- A pure tone is a sound with a sinusoidal waveform of any frequency, phase and amplitude. A pure tone is composed of a single frequency.

Perception of pitch
- high frequency corresponds to high pitch
- not linear correspondence

Humans can't hear all the sound waves. The range falls between 20 Hz and 20 000 Hz. 
Frequencies above 20 000 Hz are known as Ultrasound and below 20 Hz are known as Infrasound.

Perception of loudness
Sensation related to the amplitude of sound waves.

Sound Pressure in Pascals (SPL)

$$
SPL = 20 log_{10} (\frac{p}{p_{ref}})dB
$$
$p$ is the sound pressure, $p_{ref}$ is our reference
the smallest sound we can hear is $2.0 \cdot 10^{-5}Pa$

20 000 micro Pa in dB SPL
$$
20 log_{10} (\frac{20 000}{20}) = 20 log_{10} 1000 = 60
$$

## Digital sounds

Sounds can be represented as a function across the domain of time.

Sound wave is measured using a sound level meter to record the air pressure changes in a single point in air through time.
It uses a microphone to convert air pressure changes into electrical signals measure in volts.

### Capture and digitize sound waves

The microphone converts the air pressure changes into an electrical signals. 
The electrical energy generated by a microphone is small and we need a device called a Preamplifier to convert the weak electrical signal into a output signal strong enough to be digitized.
The ADC (Analog to Digital Converter) measures the incoming voltage some number of times every second and assigns a value to it.

![[Pasted image 20231021114353.png]]

### Playing digital audio

The DAC (Digital to Audio Converter) converts a digital signal back into an analogue electrical signal.
The Amplifier amplifies the level of the signal and sends it to a speaker.
The speakers will generate a sound wave.

![[Pasted image 20231021114415.png]]

### Sampling rate

The number of measurements (samples) take per second is called the sampling rate (Hz).
The faster we sample, the better the quality.

The ADC measures the sound waves some number of times per second. This number is called the sampling rate.

Each measurement of the waveform amplitude is called a sample.

Standard sampling rates: 44.1 kHz (CD), 48kHz (DVD), 88.2Hz, 96kHz (professional audio)
The more samples we take, the more hard disk space or memory size we need.

### The Nyquist-Shannon sampling theorem

Nyquist frequency = 1/2 x Sampling rate

Signals above the Nyquist frequency is not recorded properly by ADCs, introducing artificial frequencies in a process called aliasing.

The sampling rate must be at least twice the frequency of the signal being sampled.

#### Example

Original signal: 60Hz signal
Sampled at 50Hz
The ADC records a 10Hz signal

![[Pasted image 20231021114102.png]]

The sampling rate must be at least 120Hz to be able to take enough samples to capture the original signal.

An anti-aliasing filter is a low-pass filter that eliminates frequencies above the Nyquist frequency before audio reaches the ADC.

![[Pasted image 20231021114326.png]]

### Bit depth

Number of bits used to record the amplitude measurements.
The more bits we use, the more accurately we can measure the analogue waveform. The more hard disk space or memory size we need.

Common bit widths used for digital sound representation are 8, 16, 24, 32 bits.

#### Examples

1 bit resolution results in 2 possible values, 0 and 1.

![[Pasted image 20231021114630.png]]

2 bit resolution we have 4 possible values.

![[Pasted image 20231021114702.png]]

3 bit resolution results in 8 possible values.

![[Pasted image 20231021114723.png]]

16 bit resolution results in 65,536 possible values.

![[Pasted image 20231021114804.png]]

### Clipping

Level of the input signal is too high and the ADC cannot assign the right amplitude value. This introduces distortion.

![[Pasted image 20231021114914.png]]

### Exercise

To calculate the size of an uncompressed stereo audio file, you need to consider the sampling frequency, bit depth, and the duration of the audio. Here's how you can calculate it:

1. Sampling Frequency (44.1 kHz): This is the number of samples taken per second. In this case, it's 44,100 samples per second for each channel (left and right) in stereo audio.
2. Bit Depth (16 bits): This represents the resolution of each sample. Each sample is represented using 16 bits, which means 2^16 possible values for each sample.
3. Duration (1 minute): To calculate the total number of samples in one minute of audio, you need to multiply the sampling frequency by the duration. There are 60 seconds in a minute, so:
   Total samples = Sampling Frequency × Duration Total samples = 44,100 samples/second × 60 seconds = 2,646,000 samples for each channel (left and right)
4. Stereo Audio: Since it's stereo audio, you need to account for two channels (left and right). So, the total number of samples for both channels is:
   Total samples for stereo audio = Total samples per channel × 2 Total samples for stereo audio = 2,646,000 samples × 2 = 5,292,000 samples
5. File Size: To calculate the size of the audio file in bytes, you need to multiply the total number of samples by the bit depth and then divide by 8 (to convert bits to bytes):
   File Size (bytes) = (Total samples × Bit Depth) / 8 File Size (bytes) = (5,292,000 samples × 16 bits) / 8 File Size (bytes) = 10,584,000 bytes

So, an uncompressed stereo audio file with a duration of one minute at a sampling frequency of 44.1 kHz and a resolution of 16 bits would be approximately 10,584,000 bytes, which is equivalent to 10.1 megabytes (MB).


44,100 samples/second * 2 channels * 60 seconds * 16 bits = 84,672,000 bits.
84,672,000 bits = 10.584 MB

## Digital representation

We can represent an array of digital samples
### Time domain

![[Pasted image 20231021115515.png]]

The amplitude of the sample at the time it has been sampled. We create the signal waveform. This is also called the Waveform view.

Time can be expressed in decimal format: 1.00, 1.25, 1.50, etc... Or it can be represented as the number of the sample: 1, 2, 3, 4, 5, 6, etc...

The amplitude is represented as normalized values \[-1, 1\]  in decibels (dB FS), or sample values.
16-bit result in more than 60,000 possible values.

Decibels relative to full scale 
Does not equal dB SPL (sound pressure levels)

![[Pasted image 20231021115919.png]]

### Frequency domain

![[Pasted image 20231021115946.png]]

Show the energy of a sound. Sounds are made of millions of frequencies.

### Spectrogram

![[Pasted image 20231021120042.png]]

Similar to the Frequency domain representation. 
The spectrum changes through time.

